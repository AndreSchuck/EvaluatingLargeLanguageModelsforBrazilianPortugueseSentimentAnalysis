# Evaluating Large Language Models for Brazilian Portuguese Sentiment Analysis

This repository contains all resources, code, and data used in the research **"Evaluating Large Language Models for Brazilian Portuguese Sentiment Analysis: A Comparative Study of Multilingual State-of-the-Art vs. Brazilian Portuguese Fine-Tuned LLMs"**, submitted to the Journal of the Brazilian Computer Society (JBCS).

## üìñ About the Research

This study presents a comprehensive comparative analysis of 23 Large Language Models (LLMs) for sentiment analysis in Brazilian Portuguese texts, evaluating 13 state-of-the-art multilingual models and 10 Portuguese-specialized models through the in-context learning (ICL) paradigm.

### Key Contributions

- Comparative evaluation of large-scale LLMs (>70B parameters) vs. small-scale LLMs (<13B parameters)
- Analysis of the impact of linguistic specialization in Brazilian Portuguese
- Benchmarking across 12 public sentiment analysis datasets

## üóÇÔ∏è Repository Structure

```bash
.
‚îÇ   README.md
‚îÇ
‚îú‚îÄ‚îÄ‚îÄdatasets
‚îÇ   ‚îú‚îÄ‚îÄ‚îÄpreprocessed
‚îÇ   ‚îÇ   ‚îÇ   readme.md
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄComputer-BR
‚îÇ   ‚îÇ   ‚îÇ       computer-br_demo.csv
‚îÇ   ‚îÇ   ‚îÇ       computer-br_test.csv
‚îÇ   ‚îÇ   ‚îÇ       computer-br_train.csv
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄCorpus-4p
‚îÇ   ‚îÇ   ‚îÇ       corpus-4p_demo.csv
‚îÇ   ‚îÇ   ‚îÇ       corpus-4p_test.csv
‚îÇ   ‚îÇ   ‚îÇ       corpus-4p_train.csv
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄCSP_Eletronicos
‚îÇ   ‚îÇ   ‚îÇ       csp-eletronicos_demo.csv
‚îÇ   ‚îÇ   ‚îÇ       csp-eletronicos_test.csv
‚îÇ   ‚îÇ   ‚îÇ       csp-eletronicos_train.csv
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄCSP_Livros
‚îÇ   ‚îÇ   ‚îÇ       csp-livros_demo.csv
‚îÇ   ‚îÇ   ‚îÇ       csp-livros_test.csv
‚îÇ   ‚îÇ   ‚îÇ       csp-livros_train.csv
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄIMDB_PT
‚îÇ   ‚îÇ   ‚îÇ       imdb-pt_demo.csv
‚îÇ   ‚îÇ   ‚îÇ       imdb-pt_test.csv
‚îÇ   ‚îÇ   ‚îÇ       imdb-pt_train.csv
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄMTMSLA
‚îÇ   ‚îÇ   ‚îÇ       mtmsla_demo.csv
‚îÇ   ‚îÇ   ‚îÇ       mtmsla_test.csv
‚îÇ   ‚îÇ   ‚îÇ       mtmsla_train.csv
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄOPCovidBR
‚îÇ   ‚îÇ   ‚îÇ       opcovidbr_demo.csv
‚îÇ   ‚îÇ   ‚îÇ       opcovidbr_test.csv
‚îÇ   ‚îÇ   ‚îÇ       opcovidbr_train.csv
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄReLI
‚îÇ   ‚îÇ   ‚îÇ       reli_demo.csv
‚îÇ   ‚îÇ   ‚îÇ       reli_test.csv
‚îÇ   ‚îÇ   ‚îÇ       reli_train.csv
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄRePRO
‚îÇ   ‚îÇ   ‚îÇ       repro_demo.csv
‚îÇ   ‚îÇ   ‚îÇ       repro_test.csv
‚îÇ   ‚îÇ   ‚îÇ       repro_train.csv
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄSST2_PT
‚îÇ   ‚îÇ   ‚îÇ       sst2-pt_demo.csv
‚îÇ   ‚îÇ   ‚îÇ       sst2-pt_test.csv
‚îÇ   ‚îÇ   ‚îÇ       sst2-pt_train.csv
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ‚îÄTA-Restaurantes
‚îÇ   ‚îÇ   ‚îÇ       ta-restaurantes_demo.csv
‚îÇ   ‚îÇ   ‚îÇ       ta-restaurantes_test.csv
‚îÇ   ‚îÇ   ‚îÇ       ta-restaurantes_train.csv
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄTweetSentBR
‚îÇ   ‚îÇ           tweet-sent-br_demo.csv
‚îÇ   ‚îÇ           tweet-sent-br_test.csv
‚îÇ   ‚îÇ           tweet-sent-br_train.csv
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄraw
‚îÇ       ‚îÇ   readme.md
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄComputer-BR
‚îÇ       ‚îÇ       Computer-BR.xlsx
‚îÇ       ‚îÇ       readme.md
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄCorpus-4p
‚îÇ       ‚îÇ       10.txt
‚îÇ       ‚îÇ       11.txt
‚îÇ       ‚îÇ       30.txt
‚îÇ       ‚îÇ       31.txt
‚îÇ       ‚îÇ       readme.md
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄCSP_Eletronicos
‚îÇ       ‚îÇ       readme.md
‚îÇ       ‚îÇ       sentencas.xlsx
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄCSP_Livros
‚îÇ       ‚îÇ       corpus_book_reviews_portuguese.csv
‚îÇ       ‚îÇ       readme.md
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄIMDB_PT
‚îÇ       ‚îÇ       readme.md
‚îÇ       ‚îÇ       test-all.csv
‚îÇ       ‚îÇ       train.csv
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄMTMSLA
‚îÇ       ‚îÇ       mtmsla.xlsx
‚îÇ       ‚îÇ       readme.md
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄOPCovidBR
‚îÇ       ‚îÇ       opcovidbr.csv
‚îÇ       ‚îÇ       readme.md
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄReLI
‚îÇ       ‚îÇ       readme.md
‚îÇ       ‚îÇ       ReLi-Amado.txt
‚îÇ       ‚îÇ       ReLi-Meyer.txt
‚îÇ       ‚îÇ       ReLi-Orwell.txt
‚îÇ       ‚îÇ       ReLi-Reboucas.txt
‚îÇ       ‚îÇ       ReLi-Salinger.txt
‚îÇ       ‚îÇ       ReLi-Saramago.txt
‚îÇ       ‚îÇ       ReLi-Sheldon.txt
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄRePRO
‚îÇ       ‚îÇ       readme.md
‚îÇ       ‚îÇ       RePro.csv
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄSST2_PT
‚îÇ       ‚îÇ       readme.md
‚îÇ       ‚îÇ       train.csv
‚îÇ       ‚îÇ       validation.csv
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄTA-Restaurantes
‚îÇ       ‚îÇ       POL_restaurants.tsv
‚îÇ       ‚îÇ       readme.md
‚îÇ       ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄTweetSentBR
‚îÇ               readme.md
‚îÇ               test-00000-of-00001.parquet
‚îÇ               train-00000-of-00001.parquet
‚îÇ
‚îî‚îÄ‚îÄ‚îÄnotebooks
    ‚îú‚îÄ‚îÄ‚îÄdatasets
    ‚îÇ       datasets_preprocessing.ipynb
    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄmodels
            bode_13b.ipynb
            bode_3_1_8b_instruct_lora.ipynb
            bode_7b.ipynb
            cabrallama_3_8b.ipynb
            cabramistral_v3_7b_32k.ipynb
            claude_3_5_sonnet.ipynb
            deepseek_r1.ipynb
            deepseek_r1_distill_llama_8b.ipynb
            deepseek_r1_distill_qwen_7b.ipynb
            deepseek_v3.ipynb
            gembode_7b_instruct.ipynb
            gemini_1_5_pro.ipynb
            gemma_2_9b_instruct.ipynb
            gemma_7b_instruct.ipynb
            gpt_4o.ipynb
            Internlm_2_7b_chat.ipynb
            InternLM_chatbode_7b.ipynb
            llama_3_1_8b_instruct.ipynb
            llama_3_8b_instruct.ipynb
            qwen_2_7b_instruct.ipynb
            sabia_2_medium.ipynb
            sabia_3.ipynb
            sabia_7b.ipynb
```

## üìä Evaluated Datasets

The study utilized 12 public Brazilian Portuguese sentiment analysis datasets:

### Translated Datasets

- **IMDB_PT**: Translated movie reviews
- **SST2_PT**: Translated Stanford Sentiment Treebank

### Native Datasets

- **TweetSentBr**: Social media posts
- **ReLI**: Book reviews
- **Computer-BR**: Computer-related posts
- **MTMSLA**: Social media posts
- **CSP-Eletr√¥nicos**: Electronic product reviews
- **CSP-Livros**: Book reviews
- **4P Corpus**: Product reviews
- **RePro**: E-commerce reviews
- **OPCovidBR**: COVID-19 related posts
- **TA-Restaurantes**: Restaurant reviews

## ü§ñ Evaluated Models

### Generalist Models (>70B parameters)

- Claude-3.5-Sonnet
- GPT-4o
- Gemini-1.5-Pro
- DeepSeek-V3
- DeepSeek-R1

### PT-BR Specialized Models (>70B parameters)

- Sabi√°-3
- Sabi√°-2-Medium

### Generalist Models (<13B parameters)

- LLaMA-3/3.1-8B-Instruct
- Gemma-7B/2-9B-Instruct
- Qwen-2-7B-Instruct
- InternLM-2-7B-Chat
- DeepSeek-R1-Distill (7B/8B)

### PT-BR Specialized Models (<13B parameters)

- Bode Family (7B, 13B, 3.1-8B)
- Cabra Family (LLaMA-3-8B, Mistral-7B)
- Sabi√°-7B
- GemBode and InternLM-ChatBode variants

## üìà Main Results

- **Large-scale models** achieved accuracy exceeding 92%
- **Small-scale models** top performers reached accuracy above 90%
- **Linguistic specialization** showed mixed results, reducing hallucinations but not always improving performance
- **Newer models** consistently outperformed previous versions
- **All LLMs** significantly surpassed traditional machine learning methods

## üìã Methodology

### In-Context Learning (ICL)

- **6 demonstrations** randomly selected per dataset
- **Structured prompt** in Brazilian Portuguese with JSON specification
- **Binary classification** (positive/negative)

### Evaluation Metrics

- **Accuracy**: Primary metric
- **Macro F1 Score**: Complementary metric for imbalanced datasets
- **Hallucination rate**: Responses outside expected format

### Statistical Analysis

- **Wilcoxon test** for paired samples (Œ± = 5%)
- **Comparative analysis** between model categories

## üìÑ Citation

If you use this work, please cite:

```bibtex

```

## ü§ù Contributing

Contributions are welcome! For more information on how to contribute, see our [contribution guide](CONTRIBUTING.md).

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üë• Authors

- **Andr√© da Fonseca Schuck** - UNESP - [andre.schuck@unesp.br](mailto:andre.schuck@unesp.br)
- **Gabriel Lino Garcia** - UNESP - [gabriel.lino@unesp.br](mailto:gabriel.lino@unesp.br)
- **Jo√£o Renato Ribeiro Manesco** - UNESP - [joao.r.manesco@unesp.br](mailto:joao.r.manesco@unesp.br)
- **Pedro Henrique Paiola** - UNESP - [pedro.paiola@unesp.br](mailto:pedro.paiola@unesp.br)
- **Jo√£o Paulo Papa** - UNESP - [joao.papa@unesp.br](mailto:joao.papa@unesp.br)

## üôè Acknowledgments

We thank Maritaca AI for providing credits that made this study possible, FAPESP (grants 2013/07375-0, 2023/14427-8, and 2024/00789-8), and CNPq (grants 308529/2021-9 and 400756/2024-2) for financial support.

---

**Note**: This repository is constantly being updated. For the latest version of results and code, check the `main` branch.
