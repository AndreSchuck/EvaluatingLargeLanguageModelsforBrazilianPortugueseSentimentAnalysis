{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InPKrBOVi738"
      },
      "source": [
        "# Sabiá-3 Evaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hardware - CPU"
      ],
      "metadata": {
        "id": "fnEBXagtSInE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5f2Ei3Ei-3d"
      },
      "source": [
        "# Installations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLzGHu3VKdyh",
        "outputId": "488b76c8-1d63-49aa-86b3-df1a0e21c9af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting maritalk\n",
            "  Downloading maritalk-0.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from maritalk) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from maritalk) (4.66.5)\n",
            "Collecting httpx (from maritalk)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting tiktoken<0.8,>=0.7 (from maritalk)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from maritalk) (4.42.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.8,>=0.7->maritalk) (2024.5.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->maritalk) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->maritalk) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->maritalk) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->maritalk) (2024.7.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->maritalk) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->maritalk)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->maritalk) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->maritalk)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->maritalk) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->maritalk) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->maritalk) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->maritalk) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->maritalk) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->maritalk) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->maritalk) (0.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers->maritalk) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers->maritalk) (4.12.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->maritalk) (1.2.2)\n",
            "Downloading maritalk-0.2.6-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, tiktoken, httpcore, httpx, maritalk\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 maritalk-0.2.6 tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "! pip install maritalk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OplyZgWdjDcg"
      },
      "source": [
        "#00 - Google Drive Mount\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2OmS8YJjFk4",
        "outputId": "68ab707f-17ee-440d-b2c0-6f49d54bf9c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at ./gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwH3FsWijMf1"
      },
      "source": [
        "# 01 - Imports\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD4wmq3sjM3t"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import requests\n",
        "import maritalk\n",
        "\n",
        "from google.colab import userdata\n",
        "from pathlib import Path\n",
        "from time import sleep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8B0_VExjARi"
      },
      "source": [
        "# 02 - Constants\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FT2WF5XNjjrn"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"sabia-3\"\n",
        "\n",
        "\n",
        "PREPROCESSED_DATA_ROOT_PATH = userdata.get('IA_DATA_PREPROCESSED')\n",
        "\n",
        "\n",
        "TEST_DATASETS = {Path(dataset).stem.split(\"_test\")[0]: {\"df\": pd.read_csv(dataset), \"path\":Path(dataset).parent} for dataset in glob.glob(f'{PREPROCESSED_DATA_ROOT_PATH}/*/*_test.csv')}\n",
        "DEMO_DATASETS = {Path(dataset).stem.split(\"_demo\")[0]: {\"df\": pd.read_csv(dataset), \"path\":Path(dataset).parent} for dataset in glob.glob(f'{PREPROCESSED_DATA_ROOT_PATH}/*/*_demo.csv')}\n",
        "RESULT_DATASETS = [Path(dataset).stem.split(f\"_{MODEL_NAME}_result_v2\")[0] for dataset in glob.glob(f'{PREPROCESSED_DATA_ROOT_PATH}/*/*_{MODEL_NAME}_result_v2.csv')]\n",
        "\n",
        "\n",
        "HF_AUTH = userdata.get('HF_TOKEN')\n",
        "MARITACA_AUTH = userdata.get('MARITACA_TOKEN')\n",
        "\n",
        "\n",
        "BASE_INSTRUCTION = \"\"\"Você deverá realizar a tarefa de Classificação de Sentimento Binária em relação a polaridade de textos escritos no idioma português brasileiro considerando dois possíveis rótulos de saída: 1 para o sentimentos positivos ou -1 para negativos. A saída produzida deverá ser em formato JSON, seguindo o esquema definido entre os marcadores ```.```\n",
        "{'type': 'object','description': Objeto de saída fornecido pelo classificador após a classificação de sentimento do texto de entrada.', 'properties': {'polaridade': {'type': 'integer','description': 'Polaridade em relação ao sentimento expressado no texto de entrada. Pode assumir 2 valores: [-1, 1]','enum': [-1,1]}},\n",
        "  'required': ['polaridade']}```Considere os seguintes exemplos para realizar a predição:\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH7rdn-nvORF"
      },
      "source": [
        "# 03 - Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "733srlwQvOYH"
      },
      "outputs": [],
      "source": [
        "def generate_sorted_examples(dataframe:pd.DataFrame)->str:\n",
        "    \"\"\"\n",
        "    Generate a string of sorted examples from a DataFrame for sentiment analysis.\n",
        "\n",
        "    Args:\n",
        "        dataframe (pd.DataFrame): The DataFrame containing the examples.\n",
        "                                  It should have columns 'text' and 'label'.\n",
        "\n",
        "    Returns:\n",
        "        str: A string containing formatted examples of input text and their corresponding polarities.\n",
        "    \"\"\"\n",
        "    examples = ''\n",
        "    for i, _ in enumerate(dataframe[:3].index):\n",
        "        examples = examples + (\n",
        "        \"\\n\"\n",
        "        f\"Exemplo:\\n\"\n",
        "        f\"'entrada': '{dataframe['text'][i]}'\\n\"\n",
        "        \"'saida':{'polaridade': \" + f\"{dataframe['label'][i]}\"+\"}\"\n",
        "        \"\\n\"\n",
        "        f\"Exemplo:\\n\"\n",
        "        f\"'entrada': '{dataframe['text'][i+3]}'\\n\"\n",
        "        \"'saida':{'polaridade': \" + f\"{dataframe['label'][i+3]}\"+\"}\")\n",
        "    return examples\n",
        "\n",
        "\n",
        "def generate_classification_text(text:str)->str:\n",
        "    \"\"\"\n",
        "    Generate a formatted string for sentiment classification input and output.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text to be classified.\n",
        "\n",
        "    Returns:\n",
        "        str: A string formatted for sentiment classification showing the input text.\n",
        "    \"\"\"\n",
        "    classification = (\n",
        "        \"\\n\"\n",
        "        f\"Classificação de Sentimento:\"\n",
        "        f\"'entrada': '{text}'\"\n",
        "        \"'saida':\")\n",
        "    return classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqsp1CelvUMT"
      },
      "source": [
        "# 04 - Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hars8zSVQx5v"
      },
      "outputs": [],
      "source": [
        "for key, dataset in TEST_DATASETS.items():\n",
        "    if key not in RESULT_DATASETS:\n",
        "        print(f'Starting to evaluate dataset: {key}')\n",
        "        results_list = []\n",
        "        examples = generate_sorted_examples(DEMO_DATASETS[key]['df'])\n",
        "        instruction = BASE_INSTRUCTION + examples\n",
        "        model = maritalk.MariTalk(key=MARITACA_AUTH,\n",
        "                            model='sabia-3')\n",
        "\n",
        "        messages = []\n",
        "        messages.append({'role':'system',\n",
        "                        'content':instruction})\n",
        "\n",
        "        for index, item in enumerate(dataset['df']['text']):\n",
        "            print(index)\n",
        "            classification_text = generate_classification_text(item)\n",
        "            messages.append({'role':'user',\n",
        "                            'content':classification_text\n",
        "                            })\n",
        "\n",
        "            response = model.generate(messages,\n",
        "                                      temperature=0,\n",
        "                                      max_tokens=20,\n",
        "                                      do_sample=False)\n",
        "            sleep(5)\n",
        "            messages.pop()\n",
        "            results_list.append(response['answer'])\n",
        "\n",
        "        dataset['df']['predictions'] = results_list\n",
        "        dataset['df'].to_csv(f'{str(dataset[\"path\"])}/{key}_{MODEL_NAME}_result.csv', index=False)\n",
        "        RESULT_DATASETS = [Path(dataset).stem.split(f\"_{MODEL_NAME}_result_v2\")[0] for dataset in glob.glob(f'{PREPROCESSED_DATA_ROOT_PATH}/*/*_{MODEL_NAME}_result_v2.csv')]\n",
        "\n",
        "        print(f'The evaluation of dataset:{key} has ended.')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}